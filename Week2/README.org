All material for Week #1 is at:
https://github.com/DataTalksClub/data-engineering-zoomcamp/tree/main/week_2_workflow_orchestration

+ (2.1.1) Data Lake (GCS)
  https://www.youtube.com/watch?v=W3Zm6rjOq70&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb

  Data Lake vs Data Warehouse
  
  Basically very large unstructured data storage vs smaller structured data storage.

  ETL vs ELT
  Export Transform Load vs Export Load Transform
 
  ETL for small amount of data vs ELT for large amounts of data (i.e. Data Lake
  solution)

  Dangers of data lakes: 
   converts easily to data swamp
   no versioning
   incompatible schemas for same datab without versioning
   no metadata associated
   joins not possible

+ (2.2.1) Introduction to Workflow orchestration
  https://www.youtube.com/watch?v=8oLs6pzHp68&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=17
  
  High-level intro to workflow orchestration. The action will start in next video.

+ (2.2.2) Introduction to Prefect concepts
  (OLD) https://www.youtube.com/watch?v=jAwRCyGLKOY&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=18

  replaced by https://www.youtube.com/watch?v=cdtN6dhp708

  Here we are going to use the taxi data (as did in previous lesson, with Panda
  and PostgreSQL), but then use Prefect for workflow orchestration.

  Sample code for the rest of the week is clone in =prefect-zoomcamp=

  I keep using the de_zoomcamp conda environment I used for the first week.

  I install requirements, etc. with:

  pip install prefect -U
  pip install prefect-sqlalchemy  prefect-gcp[cloud_storage] protobuf pyarrow
              pandas-gbq psycopg2-binary

  I copy ingest_data.py and modify it to my needs. To test it, remember to start
  the docker services (go to Week1 folder and run "docker-compose up". In
  another terminal run also from Week 1, ./pgcli.sh to query the database). In a
  third terminal run python ingest_data.py and I can see the table data replaced
  in the table.

  Next we go to ingest_data_flow.py, which will use prefect, and for that we
  also need to create blocks (to handle credentials) .
  The video explains the reasoning to get to ingest_data_flow.py, doing the
  changes step by step.

  The load_data function requires prefect blocks. To access the Prefect UI
  (Orion) just run "prefect orion start" and then going to localhost:4200

  First time only? run "prefect config set PREFECT_API_URL=http://127.0.0.1:4200/api"

  Time to add a block. We need to create one for Postgres, so in Blocks we go to
  SQLAlchemyconnector. We select SyncDriver and postgresql+psycopg2, then the
  rest of values, we take them from ingest_data.py
   
  Now we can run python ingest_data_flow.py no problem. This adds table
  "yellow_trips" to ny_taxi DB (only 98027 rows, while yellow_taxi_trips has
  1369765 rows).  This is normal, since we only do one chunk and we remove trips
  where there were 0 passengers.

  
+ (2.2.3) ETL with GCP & Prefect
  https://www.youtube.com/watch?v=W-rMz_2GwqQ&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=19

  Here we are going to see how to do ETL with GCP + Prefect
  see prefect-zoomcamp/flows/02_gcp

  A lot of repetition from 2.2.2. Basically getting a file from the web and
  uploading it to GCP Bucket storage using prefect.

  I copy here etl_web_to_gcs.py (from prefect-zoomcamp/flows/02_gcp)

  Nothing especially interesting until he starts discussing function
  "write_cgs", where we deal with the blocks, credentials, GCP.

  GCS: cloud.google.com  (remember I do it with angel.vicente.garrido@gmail.com)
  I created a project named "de-zoomcamp" in Week1. Here I create a bucket,
  named "de-zoomcamp-gcs" (go  to CloudStorage -> Bucket -> create), and leave
  everything to defaults.
  In Orion UI I go to blocks and I can see that GCS Bucket and GCP credentials
  are already there, so I don't think I need to do "prefect block register -m
  prefect_gcp", but I do it just in case.

   
  Starting in minute 25 he talks about creating a GCS Bucket block, using a GCP
  credential block, which requires a service account in GCP with the right
  permissions, and a key in .json format (which I already downloaded in week 1
  to directory GCP-keys). I copy&paste the .json contents when creating the GCP
  credentials block and all is good. when running "python etl_web_to_gcs.py". 


+ (2.2.4) From Google Cloud Storage to Big Query 
  https://www.youtube.com/watch?v=Cx5jt-V5sgE&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=20

  Continuation of 2.2.3, where we will move data from GCS to Big Query (from
  data lake to data warehouse)

  I copy here etl_gcs_to_bq.py (from prefect-zoomcamp/flows/02_gcp)

  Functions extract_from_gcs and transform are trivial after having done section
  2.2.3

  The interesting one is write_bq, where we are going to save the data to a Data
  Warehouse (Big Query) in GCP. 

  We use GCPCredentials block which we created with the Orion Prefect UI in the
  previous steps (prefect orion start -> localhost:4200)

  We need (in GCP) to add data to BigQuery (ADD DATA -> Google Cloud Storage (we
  already saved it there in 2.2.3), browse and choose the .parquet file of
  interest: yellow_tripdata_2021-01.parquet). Project is already populated for
  us, and we have to create a DataSet, I call mine de_zoomcamp, in Table I
  choose "rides" -> CREATE TABLE

  To practice with the script, we can delete the data with:
  DELETE FROM `de-zoomcamp-375218.de_zoomcamp.rides` where true

  We need to fill in information about:
  + destination_table:  de_zoomcamp.rides
  + project_id: de-zoomcamp-375218

  With that the script works without troubles (I modified slightly the paths for
  local storage)  

+ (2.2.5) Parametrizing Flow & Deployments
  https://www.youtube.com/watch?v=QrDxPjX10iw&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=21

  we are using parameterized_flow.py (which I copy from prefect-zoomcamp/flows/03_deployments)
    which builds upon etl_web_to_gcs.py

    The first part (up.to minute 07:00 is very easy, since it only deals with
  parameterization, which is very simple, just adding parents-children flow
  structure).

  The caching of data in function fetch is really useful, so we don't download
  the data over and over again.


  Deployment (server side concept)

  prefect deployment build ./parameterized_flow.py:etl_parent_flow -n "Parameterized ETL"

  We can adjust the parameters here or in the UI after we apply but letâ€™s just do it here:
   - edit yaml with parameters: { "color": "yellow", "months" :[1, 2, 3], "year": 2021}

  Now we need to apply the deployment: `prefect deployment apply etl_parent_flow-deployment.yaml`

  After applying we get the message:
  View Deployment in UI: http://127.0.0.1:4200/deployments/deployment/09fc33a2-0eb4-4667-b794-cba7916b377a

  To execute flow runs from this deployment, start an agent that pulls work from the 'default' work queue:
  $ prefect agent start -q 'default'

  In the UI, we can select a "Quick Run" for this deployment, which will put
  this flow in the default queue, and the agent we just launched will take care
  of that queue and we see how the flow is being executed. 

  Last thing is that we can add notifications at the Orion UI to get
  notifications for different states in our flow (crashed, succeeded, etc.). We
  can add notifications for Slack, etc, but not sure how to send a simple
  e-mail.

+ (2.2.6) Schedules & Docker Storage with Infrastructure
  https://www.youtube.com/watch?v=psNSzqTsi-s&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=22

  Scheduling (in Oring UI -> Deployment -> Details -> Schedule)

  I can also create schedule when building the deployment, adding  something
  like: --cron "0 0 * * *" to the prefect build command.

  With --set-schedule, we can also modify the schedule for a previously created
  deployment. 

  [for deployments to run, remember that an agent has to be running, either
  locally or in the cloud, likely what we see in 2.2.7]


   Running flows in Docker containers
   ----------------------------------

   The idea here is where are we going to store our flow code. Until now we had
   it local, but we could put the code in GitHub, AWS S3, etc. but also on a
   docker container image and stored it in Docker Hub. We will see that here.

   To build the Docker image, I copy here Dockerfile and docker-requirements.txt
   (from prefect-zoomcamp)

   Let's build the Docker image:
     docker image build -t angeldevicente/de-zoomcamp-prefect:v1 .

   To push it to Docker Hub:
     docker login
     docker push angeldevicente/de-zoomcamp-prefect:v1

   Then we need to create a Docker container block, like we did earlier for GCP
   Buckets, etc. We can do it in the UI, but also programatically. I copy
   make_docker_block.py from prefect-zoomcamp/blocks and modify to suit my
   stuff. My block name is "docker-de-zoomcamp".

   Let's now make a deployment with this Docker image (but instead of building
   the deployment via the CLI, let's do it with a script). We use
   docker_deploy.py, which I copy from prefect-zoomcamp/flows/03_deployments


   prefect profile ls (to see that we are indeed in default profile)
   I run again (probably don't need it) 
      "prefect config set PREFECT_API_URL=http://127.0.0.1:4200/api"   

   We start the agent:
     prefect agent start -q 'default'

   And run the flow from the CLI:
     prefect deployment run etl-parent-flow/docker-flow

   In the terminal with the agent I can see that the flow runs without problems.

   (I put in docker parameterized_flow_docker.py and not parameterized_flow.py,
   since the last one was using the cache option, and that was giving me trouble
   (I should mount directories to indicate where to do the caching, etc. so for
   the moment I just avoid caching and it works fine.

+ (2.2.7) Prefect Cloud and Additional Resources
  https://www.youtube.com/watch?v=gGC23ZK7lr8&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=23

  documentation: docs.prefect.io
  Prefect Cloud: app.prefect.cloud
     better than running Orion locally (with automations, etc.)
  https://github.com/anna-geller
  discourse.prefect.io  (which points to Slack, twitter, etc..)


  I register at app.prefect.cloud and generate a workspace de-zoomcamp (owner is
  angeldevicenteiaces). 

  I stop orion, as we are going to be using Prefect Cloud now. In Prefect Cloud
  in my profile I generate an API key, and in sieladon I run 
  prefect cloud login -k pnu_xxxxx with the command they provide me to
  authenticate in Prefect Cloud with the default profile.

  To deploy with PrefectCloud, I can use again python github_depoy.py, but I
  will need to recreate the blocks I did locally:
    + github-de-zoomcamp-block, pointing to
      https://github.com/angel-devicente/de_zoomcamp_own

  (after login to prefectcloud it looks like the default profile gets updated in
  a way that I cannot connect to both the local orion and PrefectCloud, which
  makes sense really. If I want to be able to connect to the local Orion again,
  do:

  prefect profile create prefect_cloud
  prefect profile use prefect_cloud
  prefect cloud login -k ...

  prefect profile create local
  prefect profile use local
  prefect config set PREFECT_API_URL=http://127.0.0.1:4200/api

  (use prefect_cloud profile to interact with prefect.cloud and local to
  interact with orion)

  There is no GCS Bucket block, so I need to:
    prefect block register -m prefect_gcp (which adds GCS Bucket and GCP
    Credentials, among others)

  I recreate first GCP Credentials but when I want to recreate GCP Bucket there
  seems to be a problem: I don't see the option to include the credential.





